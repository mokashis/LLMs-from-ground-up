{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95f841a-63c9-41d4-aea1-496b3d2024dd",
   "metadata": {},
   "source": [
    "**LLM Workshop 2024 by Sebastian Raschka**\n",
    "\n",
    "This code is based on *Build a Large Language Model (From Scratch)*, [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa40e3-5109-433f-9153-f5770531fe94",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2) Understanding LLM Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5d2c0-cba8-404e-9bf3-71a218cae3cf",
   "metadata": {},
   "source": [
    "Packages that are being used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.1+cu121\n",
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42fbfd-e3c2-43c2-bc12-f5f870a0b10a",
   "metadata": {},
   "source": [
    "- This notebook provides a brief overview of the data preparation and sampling procedures to get input data \"ready\" for an LLM\n",
    "- Understanding what the input data looks like is a great first step towards understanding how LLMs work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b2922-594d-4ff9-bd82-04f1ebdf41f5",
   "metadata": {},
   "source": [
    "<img src=\"./figures/01.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbb984-8d23-40c5-bbfa-c3c379e7eec3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.1 Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c90731-7dc9-4cd3-8c4a-488e33b48e80",
   "metadata": {},
   "source": [
    "- In this section, we tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09872fdb-9d4e-40c4-949d-52a01a43ec4b",
   "metadata": {},
   "source": [
    "<img src=\"figures/02.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cceaa18-833d-46b6-b211-b20c53902805",
   "metadata": {},
   "source": [
    "- Load raw text we want to work with\n",
    "- [The Verdict by Edith Wharton](https://en.wikisource.org/wiki/The_Verdict) is a public domain short story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a769e87-470a-48b9-8bdb-12841b416198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"LLM-workshop-2024/02_data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b971a46-ac03-4368-88ae-3f20279e8f4e",
   "metadata": {},
   "source": [
    "- The goal is to tokenize and embed this text for an LLM\n",
    "- Let's develop a simple tokenizer based on some simple sample text that we can then later apply to the text above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe9330-b587-4262-be9f-497a84ec0e8a",
   "metadata": {},
   "source": [
    "<img src=\"figures/03.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa1687-2c08-485a-87cc-a93c2f9586d7",
   "metadata": {},
   "source": [
    "- The following regular expression will split on whitespaces and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737dd5b0-9dbb-4a97-9ae4-3482c8c04be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item]\n",
    "print(preprocessed[:38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35db7b5e-510b-4c45-995f-f5ad64a8e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 8405\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\", len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b419a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '--',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'Ah',\n",
       " 'Among',\n",
       " 'And',\n",
       " 'Are',\n",
       " 'Arrt',\n",
       " 'As',\n",
       " 'At',\n",
       " 'Be',\n",
       " 'Begin',\n",
       " 'Burlington',\n",
       " 'But',\n",
       " 'By',\n",
       " 'Carlo',\n",
       " 'Chicago',\n",
       " 'Claude',\n",
       " 'Come',\n",
       " 'Croft',\n",
       " 'Destroyed',\n",
       " 'Devonshire',\n",
       " 'Don',\n",
       " 'Dubarry',\n",
       " 'Emperors',\n",
       " 'Florence',\n",
       " 'For',\n",
       " 'Gallery',\n",
       " 'Gideon',\n",
       " 'Gisburn',\n",
       " 'Gisburns',\n",
       " 'Grafton',\n",
       " 'Greek',\n",
       " 'Grindle',\n",
       " 'Grindles',\n",
       " 'HAD',\n",
       " 'Had',\n",
       " 'Hang',\n",
       " 'Has',\n",
       " 'He',\n",
       " 'Her',\n",
       " 'Hermia',\n",
       " 'His',\n",
       " 'How',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'It',\n",
       " 'Jack',\n",
       " 'Jove',\n",
       " 'Just',\n",
       " 'Lord',\n",
       " 'Made',\n",
       " 'Miss',\n",
       " 'Money',\n",
       " 'Monte',\n",
       " 'Moon-dancers',\n",
       " 'Mr',\n",
       " 'Mrs',\n",
       " 'My',\n",
       " 'Never',\n",
       " 'No',\n",
       " 'Now',\n",
       " 'Nutley',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'Only',\n",
       " 'Or',\n",
       " 'Perhaps',\n",
       " 'Poor',\n",
       " 'Professional',\n",
       " 'Renaissance',\n",
       " 'Rickham',\n",
       " 'Riviera',\n",
       " 'Rome',\n",
       " 'Russian',\n",
       " 'Sevres',\n",
       " 'She',\n",
       " 'Stroud',\n",
       " 'Strouds',\n",
       " 'Suddenly',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Though',\n",
       " 'Thwing',\n",
       " 'Thwings',\n",
       " 'To',\n",
       " 'Usually',\n",
       " 'Venetian',\n",
       " 'Victor',\n",
       " 'Was',\n",
       " 'We',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Why',\n",
       " 'Yes',\n",
       " 'You',\n",
       " '_',\n",
       " 'a',\n",
       " 'abdication',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abruptly',\n",
       " 'absolute',\n",
       " 'absorbed',\n",
       " 'absurdity',\n",
       " 'academic',\n",
       " 'accuse',\n",
       " 'accustomed',\n",
       " 'across',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'added',\n",
       " 'admirers',\n",
       " 'adopted',\n",
       " 'adulation',\n",
       " 'advance',\n",
       " 'aesthetic',\n",
       " 'affect',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'again',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'air',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazement',\n",
       " 'amid',\n",
       " 'among',\n",
       " 'amplest',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'anywhere',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appointed',\n",
       " 'are',\n",
       " 'arm',\n",
       " 'arm-chair',\n",
       " 'arm-chairs',\n",
       " 'arms',\n",
       " 'art',\n",
       " 'articles',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'asked',\n",
       " 'at',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'attack',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'audacities',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'axioms',\n",
       " 'azaleas',\n",
       " 'back',\n",
       " 'background',\n",
       " 'balance',\n",
       " 'balancing',\n",
       " 'balustraded',\n",
       " 'basking',\n",
       " 'bath-rooms',\n",
       " 'be',\n",
       " 'beaming',\n",
       " 'bean-stalk',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begun',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'beneath',\n",
       " 'bespoke',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'bits',\n",
       " 'bitterness',\n",
       " 'blocked',\n",
       " 'born',\n",
       " 'borne',\n",
       " 'boudoir',\n",
       " 'bravura',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breathing',\n",
       " 'bric-a-brac',\n",
       " 'briefly',\n",
       " 'brings',\n",
       " 'bronzes',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brush',\n",
       " 'bull',\n",
       " 'business',\n",
       " 'but',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'called',\n",
       " 'came',\n",
       " 'can',\n",
       " 'canvas',\n",
       " 'canvases',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'caught',\n",
       " 'central',\n",
       " 'chair',\n",
       " 'chap',\n",
       " 'characteristic',\n",
       " 'charming',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'cheeks',\n",
       " 'chest',\n",
       " 'chimney-piece',\n",
       " 'chucked',\n",
       " 'cigar',\n",
       " 'cigarette',\n",
       " 'cigars',\n",
       " 'circulation',\n",
       " 'circumstance',\n",
       " 'circus-clown',\n",
       " 'claimed',\n",
       " 'clasping',\n",
       " 'clear',\n",
       " 'cleverer',\n",
       " 'close',\n",
       " 'clue',\n",
       " 'coat',\n",
       " 'collapsed',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'companion',\n",
       " 'compared',\n",
       " 'complex',\n",
       " 'confident',\n",
       " 'congesting',\n",
       " 'conjugal',\n",
       " 'constraint',\n",
       " 'consummate',\n",
       " 'contended',\n",
       " 'continued',\n",
       " 'corner',\n",
       " 'corrected',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'countenance',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'covered',\n",
       " 'craft',\n",
       " 'cried',\n",
       " 'crossed',\n",
       " 'crowned',\n",
       " 'crumbled',\n",
       " 'cry',\n",
       " 'cured',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'curtains',\n",
       " 'd',\n",
       " 'dabble',\n",
       " 'damask',\n",
       " 'dark',\n",
       " 'dashed',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deadening',\n",
       " 'dear',\n",
       " 'deep',\n",
       " 'deerhound',\n",
       " 'degree',\n",
       " 'delicate',\n",
       " 'demand',\n",
       " 'denied',\n",
       " 'deploring',\n",
       " 'deprecating',\n",
       " 'deprecatingly',\n",
       " 'desire',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'desultory',\n",
       " 'detail',\n",
       " 'diagnosis',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'died',\n",
       " 'dim',\n",
       " 'dimmest',\n",
       " 'dingy',\n",
       " 'dining-room',\n",
       " 'disarming',\n",
       " 'discovery',\n",
       " 'discrimination',\n",
       " 'discussion',\n",
       " 'disdain',\n",
       " 'disdained',\n",
       " 'disease',\n",
       " 'disguised',\n",
       " 'display',\n",
       " 'dissatisfied',\n",
       " 'distinguished',\n",
       " 'distract',\n",
       " 'divert',\n",
       " 'do',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donkey',\n",
       " 'down',\n",
       " 'dozen',\n",
       " 'dragged',\n",
       " 'drawing-room',\n",
       " 'drawing-rooms',\n",
       " 'drawn',\n",
       " 'dress-closets',\n",
       " 'drew',\n",
       " 'dropped',\n",
       " 'each',\n",
       " 'earth',\n",
       " 'ease',\n",
       " 'easel',\n",
       " 'easy',\n",
       " 'echoed',\n",
       " 'economy',\n",
       " 'effect',\n",
       " 'effects',\n",
       " 'efforts',\n",
       " 'egregious',\n",
       " 'eighteenth-century',\n",
       " 'elbow',\n",
       " 'elegant',\n",
       " 'else',\n",
       " 'embarrassed',\n",
       " 'enabled',\n",
       " 'end',\n",
       " 'endless',\n",
       " 'enjoy',\n",
       " 'enlightenment',\n",
       " 'enough',\n",
       " 'ensuing',\n",
       " 'equally',\n",
       " 'equanimity',\n",
       " 'escape',\n",
       " 'established',\n",
       " 'etching',\n",
       " 'even',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'everlasting',\n",
       " 'every',\n",
       " 'exasperated',\n",
       " 'except',\n",
       " 'excuse',\n",
       " 'excusing',\n",
       " 'existed',\n",
       " 'expected',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'extenuation',\n",
       " 'exterminating',\n",
       " 'extracting',\n",
       " 'eye',\n",
       " 'eyebrows',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'fact',\n",
       " 'faded',\n",
       " 'failed',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'faith',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'famille-verte',\n",
       " 'fancy',\n",
       " 'fashionable',\n",
       " 'fate',\n",
       " 'feather',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'fewer',\n",
       " 'finality',\n",
       " 'find',\n",
       " 'fingers',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fitting',\n",
       " 'five',\n",
       " 'flash',\n",
       " 'flashed',\n",
       " 'florid',\n",
       " 'flowers',\n",
       " 'fluently',\n",
       " 'flung',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'fond',\n",
       " 'footstep',\n",
       " 'for',\n",
       " 'forced',\n",
       " 'forcing',\n",
       " 'forehead',\n",
       " 'foreign',\n",
       " 'foreseen',\n",
       " 'forgive',\n",
       " 'forgotten',\n",
       " 'form',\n",
       " 'formed',\n",
       " 'forming',\n",
       " 'forward',\n",
       " 'fostered',\n",
       " 'found',\n",
       " 'foundations',\n",
       " 'fragment',\n",
       " 'fragments',\n",
       " 'frame',\n",
       " 'frames',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fullest',\n",
       " 'furiously',\n",
       " 'furrowed',\n",
       " 'garlanded',\n",
       " 'garlands',\n",
       " 'gave',\n",
       " 'genial',\n",
       " 'genius',\n",
       " 'gesture',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'glanced',\n",
       " 'glimpse',\n",
       " 'gloried',\n",
       " 'glory',\n",
       " 'go',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'good-breeding',\n",
       " 'good-humoured',\n",
       " 'got',\n",
       " 'grace',\n",
       " 'gradually',\n",
       " 'gray',\n",
       " 'grayish',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'grew',\n",
       " 'groping',\n",
       " 'growing',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'half-light',\n",
       " 'half-mechanically',\n",
       " 'hall',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'handsome',\n",
       " 'hanging',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'hard',\n",
       " 'hardly',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'height',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hermit',\n",
       " 'herself',\n",
       " 'hesitations',\n",
       " 'hide',\n",
       " 'high',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'hint',\n",
       " 'his',\n",
       " 'history',\n",
       " 'holding',\n",
       " 'home',\n",
       " 'honour',\n",
       " 'hooded',\n",
       " 'hostess',\n",
       " 'hot-house',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'hung',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'idle',\n",
       " 'idling',\n",
       " 'if',\n",
       " 'immediately',\n",
       " 'in',\n",
       " 'incense',\n",
       " 'indifferent',\n",
       " 'inevitable',\n",
       " 'inevitably',\n",
       " 'inflexible',\n",
       " 'insensible',\n",
       " 'insignificant',\n",
       " 'instinctively',\n",
       " 'instructive',\n",
       " 'interesting',\n",
       " 'into',\n",
       " 'ironic',\n",
       " 'irony',\n",
       " 'irrelevance',\n",
       " 'irrevocable',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'jardiniere',\n",
       " 'jealousy',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kind',\n",
       " 'knees',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'laid',\n",
       " 'lair',\n",
       " 'landing',\n",
       " 'language',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'laugh',\n",
       " 'laughed',\n",
       " 'lay',\n",
       " 'leading',\n",
       " 'lean',\n",
       " 'learned',\n",
       " 'least',\n",
       " 'leathery',\n",
       " 'leave',\n",
       " 'led',\n",
       " 'left',\n",
       " 'leisure',\n",
       " 'lends',\n",
       " 'lent',\n",
       " 'let',\n",
       " 'lies',\n",
       " 'life',\n",
       " 'life-likeness',\n",
       " 'lift',\n",
       " 'lifted',\n",
       " 'light',\n",
       " 'lightly',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'lingered',\n",
       " 'lips',\n",
       " 'lit',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'loathing',\n",
       " 'long',\n",
       " 'longed',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lounging',\n",
       " 'lovely',\n",
       " 'lucky',\n",
       " 'lump',\n",
       " 'luncheon-table',\n",
       " 'luxury',\n",
       " 'lying',\n",
       " 'made',\n",
       " 'make',\n",
       " 'man',\n",
       " 'manage',\n",
       " 'managed',\n",
       " 'mantel-piece',\n",
       " 'marble',\n",
       " 'married',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meant',\n",
       " 'mediocrity',\n",
       " 'medium',\n",
       " 'mentioned',\n",
       " 'mere',\n",
       " 'merely',\n",
       " 'met',\n",
       " 'might',\n",
       " 'mighty',\n",
       " 'millionaire',\n",
       " 'mine',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'mirrors',\n",
       " 'modest',\n",
       " 'modesty',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'monumental',\n",
       " 'mood',\n",
       " 'morbidly',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mourn',\n",
       " 'mourned',\n",
       " 'moustache',\n",
       " 'moved',\n",
       " 'much',\n",
       " 'muddling',\n",
       " 'multiplied',\n",
       " 'murmur',\n",
       " 'muscles',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'mysterious',\n",
       " 'naive',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'negatived',\n",
       " 'nervous',\n",
       " 'nervousness',\n",
       " 'neutral',\n",
       " 'never',\n",
       " 'next',\n",
       " 'no',\n",
       " 'none',\n",
       " 'not',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nymphs',\n",
       " 'oak',\n",
       " 'obituary',\n",
       " 'object',\n",
       " 'objects',\n",
       " 'occurred',\n",
       " 'oddly',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'open',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outline',\n",
       " 'oval',\n",
       " 'over',\n",
       " 'own',\n",
       " 'packed',\n",
       " 'paid',\n",
       " 'paint',\n",
       " 'painted',\n",
       " 'painter',\n",
       " 'painting',\n",
       " 'pale',\n",
       " 'paled',\n",
       " 'palm-trees',\n",
       " 'panel',\n",
       " 'panelling',\n",
       " 'pardonable',\n",
       " 'pardoned',\n",
       " 'part',\n",
       " 'passages',\n",
       " 'passing',\n",
       " 'past',\n",
       " 'pastels',\n",
       " 'pathos',\n",
       " 'patient',\n",
       " 'people',\n",
       " 'perceptible',\n",
       " 'perfect',\n",
       " 'persistence',\n",
       " 'persuasively',\n",
       " 'phrase',\n",
       " 'picture',\n",
       " 'pictures',\n",
       " 'pines',\n",
       " 'pink',\n",
       " 'place',\n",
       " 'placed',\n",
       " 'plain',\n",
       " 'platitudes',\n",
       " 'pleased',\n",
       " 'pockets',\n",
       " 'point',\n",
       " 'poised',\n",
       " 'poor',\n",
       " 'portrait',\n",
       " 'posing',\n",
       " 'possessed',\n",
       " 'poverty',\n",
       " 'predicted',\n",
       " 'preliminary',\n",
       " 'presenting',\n",
       " 'prestidigitation',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'pride',\n",
       " 'princely',\n",
       " 'prism',\n",
       " 'problem',\n",
       " 'proclaiming',\n",
       " 'prodigious',\n",
       " 'profusion',\n",
       " 'protest',\n",
       " 'prove',\n",
       " 'public',\n",
       " 'purblind',\n",
       " 'purely',\n",
       " 'pushed',\n",
       " 'put',\n",
       " 'qualities',\n",
       " 'quality',\n",
       " 'queerly',\n",
       " 'question',\n",
       " 'quickly',\n",
       " 'quietly',\n",
       " 'quite',\n",
       " 'quote',\n",
       " 'rain',\n",
       " 'raised',\n",
       " 'random',\n",
       " 'rather',\n",
       " 're',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reared',\n",
       " 'reason',\n",
       " 'reassurance',\n",
       " 'recovering',\n",
       " 'recreated',\n",
       " 'reflected',\n",
       " 'reflection',\n",
       " 'regrets',\n",
       " 'relatively',\n",
       " 'remained',\n",
       " 'remember',\n",
       " 'reminded',\n",
       " 'repeating',\n",
       " 'represented',\n",
       " 'reproduction',\n",
       " 'resented',\n",
       " 'resolve',\n",
       " 'resources',\n",
       " 'rest',\n",
       " 'rich',\n",
       " 'ridiculous',\n",
       " 'robbed',\n",
       " 'romantic',\n",
       " 'room',\n",
       " 'rose',\n",
       " 'rs',\n",
       " 'rule',\n",
       " 'run',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'satisfaction',\n",
       " 'savour',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scorn',\n",
       " 'scornful',\n",
       " 'secret',\n",
       " 'see',\n",
       " 'seemed',\n",
       " 'seen',\n",
       " 'self-confident',\n",
       " 'send',\n",
       " 'sensation',\n",
       " 'sensitive',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'set',\n",
       " 'sex',\n",
       " 'shade',\n",
       " 'shaking',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'shirked',\n",
       " 'short',\n",
       " 'should',\n",
       " 'shoulder',\n",
       " 'shoulders',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'showy',\n",
       " 'shrug',\n",
       " 'shrugged',\n",
       " 'sight',\n",
       " 'sign',\n",
       " 'silent',\n",
       " 'silver',\n",
       " 'similar',\n",
       " 'simpleton',\n",
       " 'simplifications',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'single',\n",
       " 'sitter',\n",
       " 'sitters',\n",
       " 'sketch',\n",
       " 'skill',\n",
       " 'slight',\n",
       " 'slightly',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'sneer',\n",
       " 'so',\n",
       " 'solace',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'something',\n",
       " 'spacious',\n",
       " 'spaniel',\n",
       " 'speaking-tubes',\n",
       " 'speculations',\n",
       " 'spite',\n",
       " 'splash',\n",
       " 'square',\n",
       " 'stairs',\n",
       " 'stammer',\n",
       " 'stand',\n",
       " 'standing',\n",
       " 'started',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'stocked',\n",
       " 'stood',\n",
       " 'stopped',\n",
       " 'stopping',\n",
       " 'straddling',\n",
       " 'straight',\n",
       " 'strain',\n",
       " 'straining',\n",
       " 'strange',\n",
       " 'straw',\n",
       " 'stream',\n",
       " 'stroke',\n",
       " 'strokes',\n",
       " 'strolled',\n",
       " 'strongest',\n",
       " 'strongly',\n",
       " 'struck',\n",
       " 'studio',\n",
       " 'stuff',\n",
       " 'subject',\n",
       " 'substantial',\n",
       " 'suburban',\n",
       " 'such',\n",
       " 'suddenly',\n",
       " 'suffered',\n",
       " 'sugar',\n",
       " 'suggested',\n",
       " 'sunburn',\n",
       " 'sunburnt',\n",
       " 'sunlit',\n",
       " 'superb',\n",
       " 'sure',\n",
       " 'surest',\n",
       " 'surface',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surrounded',\n",
       " 'suspected',\n",
       " 'sweetly',\n",
       " 'sweetness',\n",
       " 'swelling',\n",
       " 'swept',\n",
       " 'swum',\n",
       " 't',\n",
       " 'table',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'talking',\n",
       " 'tea',\n",
       " 'tears',\n",
       " 'technicalities',\n",
       " 'technique',\n",
       " 'tell',\n",
       " 'tells',\n",
       " 'tempting',\n",
       " 'terra-cotta',\n",
       " 'terrace',\n",
       " 'terraces',\n",
       " 'terribly',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'they',\n",
       " 'thin',\n",
       " 'thing',\n",
       " 'things',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(preprocessed))     #unique tokens\n",
    "sorted(set(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.2 Converting tokens into token IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5204973-f414-4c0d-87b0-cfec1f06e6ff",
   "metadata": {},
   "source": [
    "- Next, we convert the text tokens into token IDs that we can process via embedding layers later\n",
    "- For this we first need to build a vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b041d-f739-43b8-bd81-0443ae3a7f8d",
   "metadata": {},
   "source": [
    "<img src=\"figures/04.png\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeade64-037b-4b59-9039-d3b000ef8886",
   "metadata": {},
   "source": [
    "- The vocabulary contains the unique words in the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdf0533-5ab6-42a5-83fa-a3b045de6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d00d96-881f-4691-bb03-84fec2a75a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '--': 8, '.': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'Ah': 14, 'Among': 15, 'And': 16, 'Are': 17, 'Arrt': 18, 'As': 19, 'At': 20, 'Be': 21, 'Begin': 22, 'Burlington': 23, 'But': 24, 'By': 25, 'Carlo': 26, 'Chicago': 27, 'Claude': 28, 'Come': 29, 'Croft': 30, 'Destroyed': 31, 'Devonshire': 32, 'Don': 33, 'Dubarry': 34, 'Emperors': 35, 'Florence': 36, 'For': 37, 'Gallery': 38, 'Gideon': 39, 'Gisburn': 40, 'Gisburns': 41, 'Grafton': 42, 'Greek': 43, 'Grindle': 44, 'Grindles': 45, 'HAD': 46, 'Had': 47, 'Hang': 48, 'Has': 49, 'He': 50, 'Her': 51, 'Hermia': 52, 'His': 53, 'How': 54, 'I': 55, 'If': 56, 'In': 57, 'It': 58, 'Jack': 59, 'Jove': 60, 'Just': 61, 'Lord': 62, 'Made': 63, 'Miss': 64, 'Money': 65, 'Monte': 66, 'Moon-dancers': 67, 'Mr': 68, 'Mrs': 69, 'My': 70, 'Never': 71, 'No': 72, 'Now': 73, 'Nutley': 74, 'Of': 75, 'Oh': 76, 'On': 77, 'Once': 78, 'Only': 79, 'Or': 80, 'Perhaps': 81, 'Poor': 82, 'Professional': 83, 'Renaissance': 84, 'Rickham': 85, 'Riviera': 86, 'Rome': 87, 'Russian': 88, 'Sevres': 89, 'She': 90, 'Stroud': 91, 'Strouds': 92, 'Suddenly': 93, 'That': 94, 'The': 95, 'Then': 96, 'There': 97, 'They': 98, 'This': 99, 'Those': 100, 'Though': 101, 'Thwing': 102, 'Thwings': 103, 'To': 104, 'Usually': 105, 'Venetian': 106, 'Victor': 107, 'Was': 108, 'We': 109, 'Well': 110, 'What': 111, 'When': 112, 'Why': 113, 'Yes': 114, 'You': 115, '_': 116, 'a': 117, 'abdication': 118, 'able': 119, 'about': 120, 'above': 121, 'abruptly': 122, 'absolute': 123, 'absorbed': 124, 'absurdity': 125, 'academic': 126, 'accuse': 127, 'accustomed': 128, 'across': 129, 'activity': 130, 'add': 131, 'added': 132, 'admirers': 133, 'adopted': 134, 'adulation': 135, 'advance': 136, 'aesthetic': 137, 'affect': 138, 'afraid': 139, 'after': 140, 'afterward': 141, 'again': 142, 'ago': 143, 'ah': 144, 'air': 145, 'alive': 146, 'all': 147, 'almost': 148, 'alone': 149, 'along': 150, 'always': 151, 'am': 152, 'amazement': 153, 'amid': 154, 'among': 155, 'amplest': 156, 'amusing': 157, 'an': 158, 'and': 159, 'another': 160, 'answer': 161, 'answered': 162, 'any': 163, 'anything': 164, 'anywhere': 165, 'apparent': 166, 'apparently': 167, 'appearance': 168, 'appeared': 169, 'appointed': 170, 'are': 171, 'arm': 172, 'arm-chair': 173, 'arm-chairs': 174, 'arms': 175, 'art': 176, 'articles': 177, 'artist': 178, 'as': 179, 'aside': 180, 'asked': 181, 'at': 182, 'atmosphere': 183, 'atom': 184, 'attack': 185, 'attention': 186, 'attitude': 187, 'audacities': 188, 'away': 189, 'awful': 190, 'axioms': 191, 'azaleas': 192, 'back': 193, 'background': 194, 'balance': 195, 'balancing': 196, 'balustraded': 197, 'basking': 198, 'bath-rooms': 199, 'be': 200, 'beaming': 201, 'bean-stalk': 202, 'bear': 203, 'beard': 204, 'beauty': 205, 'became': 206, 'because': 207, 'becoming': 208, 'bed': 209, 'been': 210, 'before': 211, 'began': 212, 'begun': 213, 'behind': 214, 'being': 215, 'believed': 216, 'beneath': 217, 'bespoke': 218, 'better': 219, 'between': 220, 'big': 221, 'bits': 222, 'bitterness': 223, 'blocked': 224, 'born': 225, 'borne': 226, 'boudoir': 227, 'bravura': 228, 'break': 229, 'breaking': 230, 'breathing': 231, 'bric-a-brac': 232, 'briefly': 233, 'brings': 234, 'bronzes': 235, 'brought': 236, 'brown': 237, 'brush': 238, 'bull': 239, 'business': 240, 'but': 241, 'buying': 242, 'by': 243, 'called': 244, 'came': 245, 'can': 246, 'canvas': 247, 'canvases': 248, 'cards': 249, 'care': 250, 'career': 251, 'caught': 252, 'central': 253, 'chair': 254, 'chap': 255, 'characteristic': 256, 'charming': 257, 'cheap': 258, 'check': 259, 'cheeks': 260, 'chest': 261, 'chimney-piece': 262, 'chucked': 263, 'cigar': 264, 'cigarette': 265, 'cigars': 266, 'circulation': 267, 'circumstance': 268, 'circus-clown': 269, 'claimed': 270, 'clasping': 271, 'clear': 272, 'cleverer': 273, 'close': 274, 'clue': 275, 'coat': 276, 'collapsed': 277, 'colour': 278, 'come': 279, 'comfortable': 280, 'coming': 281, 'companion': 282, 'compared': 283, 'complex': 284, 'confident': 285, 'congesting': 286, 'conjugal': 287, 'constraint': 288, 'consummate': 289, 'contended': 290, 'continued': 291, 'corner': 292, 'corrected': 293, 'could': 294, 'couldn': 295, 'count': 296, 'countenance': 297, 'couple': 298, 'course': 299, 'covered': 300, 'craft': 301, 'cried': 302, 'crossed': 303, 'crowned': 304, 'crumbled': 305, 'cry': 306, 'cured': 307, 'curiosity': 308, 'curious': 309, 'current': 310, 'curtains': 311, 'd': 312, 'dabble': 313, 'damask': 314, 'dark': 315, 'dashed': 316, 'day': 317, 'days': 318, 'dead': 319, 'deadening': 320, 'dear': 321, 'deep': 322, 'deerhound': 323, 'degree': 324, 'delicate': 325, 'demand': 326, 'denied': 327, 'deploring': 328, 'deprecating': 329, 'deprecatingly': 330, 'desire': 331, 'destroyed': 332, 'destruction': 333, 'desultory': 334, 'detail': 335, 'diagnosis': 336, 'did': 337, 'didn': 338, 'died': 339, 'dim': 340, 'dimmest': 341, 'dingy': 342, 'dining-room': 343, 'disarming': 344, 'discovery': 345, 'discrimination': 346, 'discussion': 347, 'disdain': 348, 'disdained': 349, 'disease': 350, 'disguised': 351, 'display': 352, 'dissatisfied': 353, 'distinguished': 354, 'distract': 355, 'divert': 356, 'do': 357, 'doesn': 358, 'doing': 359, 'domestic': 360, 'don': 361, 'done': 362, 'donkey': 363, 'down': 364, 'dozen': 365, 'dragged': 366, 'drawing-room': 367, 'drawing-rooms': 368, 'drawn': 369, 'dress-closets': 370, 'drew': 371, 'dropped': 372, 'each': 373, 'earth': 374, 'ease': 375, 'easel': 376, 'easy': 377, 'echoed': 378, 'economy': 379, 'effect': 380, 'effects': 381, 'efforts': 382, 'egregious': 383, 'eighteenth-century': 384, 'elbow': 385, 'elegant': 386, 'else': 387, 'embarrassed': 388, 'enabled': 389, 'end': 390, 'endless': 391, 'enjoy': 392, 'enlightenment': 393, 'enough': 394, 'ensuing': 395, 'equally': 396, 'equanimity': 397, 'escape': 398, 'established': 399, 'etching': 400, 'even': 401, 'event': 402, 'ever': 403, 'everlasting': 404, 'every': 405, 'exasperated': 406, 'except': 407, 'excuse': 408, 'excusing': 409, 'existed': 410, 'expected': 411, 'exquisite': 412, 'exquisitely': 413, 'extenuation': 414, 'exterminating': 415, 'extracting': 416, 'eye': 417, 'eyebrows': 418, 'eyes': 419, 'face': 420, 'faces': 421, 'fact': 422, 'faded': 423, 'failed': 424, 'failure': 425, 'fair': 426, 'faith': 427, 'false': 428, 'familiar': 429, 'famille-verte': 430, 'fancy': 431, 'fashionable': 432, 'fate': 433, 'feather': 434, 'feet': 435, 'fell': 436, 'fellow': 437, 'felt': 438, 'few': 439, 'fewer': 440, 'finality': 441, 'find': 442, 'fingers': 443, 'first': 444, 'fit': 445, 'fitting': 446, 'five': 447, 'flash': 448, 'flashed': 449, 'florid': 450, 'flowers': 451, 'fluently': 452, 'flung': 453, 'follow': 454, 'followed': 455, 'fond': 456, 'footstep': 457, 'for': 458, 'forced': 459, 'forcing': 460, 'forehead': 461, 'foreign': 462, 'foreseen': 463, 'forgive': 464, 'forgotten': 465, 'form': 466, 'formed': 467, 'forming': 468, 'forward': 469, 'fostered': 470, 'found': 471, 'foundations': 472, 'fragment': 473, 'fragments': 474, 'frame': 475, 'frames': 476, 'frequently': 477, 'friend': 478, 'from': 479, 'full': 480, 'fullest': 481, 'furiously': 482, 'furrowed': 483, 'garlanded': 484, 'garlands': 485, 'gave': 486, 'genial': 487, 'genius': 488, 'gesture': 489, 'get': 490, 'getting': 491, 'give': 492, 'given': 493, 'glad': 494, 'glanced': 495, 'glimpse': 496, 'gloried': 497, 'glory': 498, 'go': 499, 'going': 500, 'gone': 501, 'good': 502, 'good-breeding': 503, 'good-humoured': 504, 'got': 505, 'grace': 506, 'gradually': 507, 'gray': 508, 'grayish': 509, 'great': 510, 'greatest': 511, 'greatness': 512, 'grew': 513, 'groping': 514, 'growing': 515, 'had': 516, 'hadn': 517, 'hair': 518, 'half': 519, 'half-light': 520, 'half-mechanically': 521, 'hall': 522, 'hand': 523, 'hands': 524, 'handsome': 525, 'hanging': 526, 'happen': 527, 'happened': 528, 'hard': 529, 'hardly': 530, 'has': 531, 'have': 532, 'haven': 533, 'having': 534, 'he': 535, 'head': 536, 'hear': 537, 'heard': 538, 'heart': 539, 'height': 540, 'her': 541, 'here': 542, 'hermit': 543, 'herself': 544, 'hesitations': 545, 'hide': 546, 'high': 547, 'him': 548, 'himself': 549, 'hint': 550, 'his': 551, 'history': 552, 'holding': 553, 'home': 554, 'honour': 555, 'hooded': 556, 'hostess': 557, 'hot-house': 558, 'hour': 559, 'hours': 560, 'house': 561, 'how': 562, 'hung': 563, 'husband': 564, 'idea': 565, 'idle': 566, 'idling': 567, 'if': 568, 'immediately': 569, 'in': 570, 'incense': 571, 'indifferent': 572, 'inevitable': 573, 'inevitably': 574, 'inflexible': 575, 'insensible': 576, 'insignificant': 577, 'instinctively': 578, 'instructive': 579, 'interesting': 580, 'into': 581, 'ironic': 582, 'irony': 583, 'irrelevance': 584, 'irrevocable': 585, 'is': 586, 'it': 587, 'its': 588, 'itself': 589, 'jardiniere': 590, 'jealousy': 591, 'just': 592, 'keep': 593, 'kept': 594, 'kind': 595, 'knees': 596, 'knew': 597, 'know': 598, 'known': 599, 'laid': 600, 'lair': 601, 'landing': 602, 'language': 603, 'last': 604, 'late': 605, 'later': 606, 'latter': 607, 'laugh': 608, 'laughed': 609, 'lay': 610, 'leading': 611, 'lean': 612, 'learned': 613, 'least': 614, 'leathery': 615, 'leave': 616, 'led': 617, 'left': 618, 'leisure': 619, 'lends': 620, 'lent': 621, 'let': 622, 'lies': 623, 'life': 624, 'life-likeness': 625, 'lift': 626, 'lifted': 627, 'light': 628, 'lightly': 629, 'like': 630, 'liked': 631, 'line': 632, 'lines': 633, 'lingered': 634, 'lips': 635, 'lit': 636, 'little': 637, 'live': 638, 'll': 639, 'loathing': 640, 'long': 641, 'longed': 642, 'longer': 643, 'look': 644, 'looked': 645, 'looking': 646, 'lose': 647, 'loss': 648, 'lounging': 649, 'lovely': 650, 'lucky': 651, 'lump': 652, 'luncheon-table': 653, 'luxury': 654, 'lying': 655, 'made': 656, 'make': 657, 'man': 658, 'manage': 659, 'managed': 660, 'mantel-piece': 661, 'marble': 662, 'married': 663, 'may': 664, 'me': 665, 'meant': 666, 'mediocrity': 667, 'medium': 668, 'mentioned': 669, 'mere': 670, 'merely': 671, 'met': 672, 'might': 673, 'mighty': 674, 'millionaire': 675, 'mine': 676, 'minute': 677, 'minutes': 678, 'mirrors': 679, 'modest': 680, 'modesty': 681, 'moment': 682, 'money': 683, 'monumental': 684, 'mood': 685, 'morbidly': 686, 'more': 687, 'most': 688, 'mourn': 689, 'mourned': 690, 'moustache': 691, 'moved': 692, 'much': 693, 'muddling': 694, 'multiplied': 695, 'murmur': 696, 'muscles': 697, 'must': 698, 'my': 699, 'myself': 700, 'mysterious': 701, 'naive': 702, 'near': 703, 'nearly': 704, 'negatived': 705, 'nervous': 706, 'nervousness': 707, 'neutral': 708, 'never': 709, 'next': 710, 'no': 711, 'none': 712, 'not': 713, 'note': 714, 'nothing': 715, 'now': 716, 'nymphs': 717, 'oak': 718, 'obituary': 719, 'object': 720, 'objects': 721, 'occurred': 722, 'oddly': 723, 'of': 724, 'off': 725, 'often': 726, 'oh': 727, 'old': 728, 'on': 729, 'once': 730, 'one': 731, 'ones': 732, 'only': 733, 'onto': 734, 'open': 735, 'or': 736, 'other': 737, 'our': 738, 'ourselves': 739, 'out': 740, 'outline': 741, 'oval': 742, 'over': 743, 'own': 744, 'packed': 745, 'paid': 746, 'paint': 747, 'painted': 748, 'painter': 749, 'painting': 750, 'pale': 751, 'paled': 752, 'palm-trees': 753, 'panel': 754, 'panelling': 755, 'pardonable': 756, 'pardoned': 757, 'part': 758, 'passages': 759, 'passing': 760, 'past': 761, 'pastels': 762, 'pathos': 763, 'patient': 764, 'people': 765, 'perceptible': 766, 'perfect': 767, 'persistence': 768, 'persuasively': 769, 'phrase': 770, 'picture': 771, 'pictures': 772, 'pines': 773, 'pink': 774, 'place': 775, 'placed': 776, 'plain': 777, 'platitudes': 778, 'pleased': 779, 'pockets': 780, 'point': 781, 'poised': 782, 'poor': 783, 'portrait': 784, 'posing': 785, 'possessed': 786, 'poverty': 787, 'predicted': 788, 'preliminary': 789, 'presenting': 790, 'prestidigitation': 791, 'pretty': 792, 'previous': 793, 'price': 794, 'pride': 795, 'princely': 796, 'prism': 797, 'problem': 798, 'proclaiming': 799, 'prodigious': 800, 'profusion': 801, 'protest': 802, 'prove': 803, 'public': 804, 'purblind': 805, 'purely': 806, 'pushed': 807, 'put': 808, 'qualities': 809, 'quality': 810, 'queerly': 811, 'question': 812, 'quickly': 813, 'quietly': 814, 'quite': 815, 'quote': 816, 'rain': 817, 'raised': 818, 'random': 819, 'rather': 820, 're': 821, 'real': 822, 'really': 823, 'reared': 824, 'reason': 825, 'reassurance': 826, 'recovering': 827, 'recreated': 828, 'reflected': 829, 'reflection': 830, 'regrets': 831, 'relatively': 832, 'remained': 833, 'remember': 834, 'reminded': 835, 'repeating': 836, 'represented': 837, 'reproduction': 838, 'resented': 839, 'resolve': 840, 'resources': 841, 'rest': 842, 'rich': 843, 'ridiculous': 844, 'robbed': 845, 'romantic': 846, 'room': 847, 'rose': 848, 'rs': 849, 'rule': 850, 'run': 851, 's': 852, 'said': 853, 'same': 854, 'satisfaction': 855, 'savour': 856, 'saw': 857, 'say': 858, 'saying': 859, 'says': 860, 'scorn': 861, 'scornful': 862, 'secret': 863, 'see': 864, 'seemed': 865, 'seen': 866, 'self-confident': 867, 'send': 868, 'sensation': 869, 'sensitive': 870, 'sent': 871, 'serious': 872, 'set': 873, 'sex': 874, 'shade': 875, 'shaking': 876, 'shall': 877, 'she': 878, 'shirked': 879, 'short': 880, 'should': 881, 'shoulder': 882, 'shoulders': 883, 'show': 884, 'showed': 885, 'showy': 886, 'shrug': 887, 'shrugged': 888, 'sight': 889, 'sign': 890, 'silent': 891, 'silver': 892, 'similar': 893, 'simpleton': 894, 'simplifications': 895, 'simply': 896, 'since': 897, 'single': 898, 'sitter': 899, 'sitters': 900, 'sketch': 901, 'skill': 902, 'slight': 903, 'slightly': 904, 'slowly': 905, 'small': 906, 'smile': 907, 'smiling': 908, 'sneer': 909, 'so': 910, 'solace': 911, 'some': 912, 'somebody': 913, 'something': 914, 'spacious': 915, 'spaniel': 916, 'speaking-tubes': 917, 'speculations': 918, 'spite': 919, 'splash': 920, 'square': 921, 'stairs': 922, 'stammer': 923, 'stand': 924, 'standing': 925, 'started': 926, 'stay': 927, 'still': 928, 'stocked': 929, 'stood': 930, 'stopped': 931, 'stopping': 932, 'straddling': 933, 'straight': 934, 'strain': 935, 'straining': 936, 'strange': 937, 'straw': 938, 'stream': 939, 'stroke': 940, 'strokes': 941, 'strolled': 942, 'strongest': 943, 'strongly': 944, 'struck': 945, 'studio': 946, 'stuff': 947, 'subject': 948, 'substantial': 949, 'suburban': 950, 'such': 951, 'suddenly': 952, 'suffered': 953, 'sugar': 954, 'suggested': 955, 'sunburn': 956, 'sunburnt': 957, 'sunlit': 958, 'superb': 959, 'sure': 960, 'surest': 961, 'surface': 962, 'surprise': 963, 'surprised': 964, 'surrounded': 965, 'suspected': 966, 'sweetly': 967, 'sweetness': 968, 'swelling': 969, 'swept': 970, 'swum': 971, 't': 972, 'table': 973, 'take': 974, 'taken': 975, 'talking': 976, 'tea': 977, 'tears': 978, 'technicalities': 979, 'technique': 980, 'tell': 981, 'tells': 982, 'tempting': 983, 'terra-cotta': 984, 'terrace': 985, 'terraces': 986, 'terribly': 987, 'than': 988, 'that': 989, 'the': 990, 'their': 991, 'them': 992, 'then': 993, 'there': 994, 'therefore': 995, 'they': 996, 'thin': 997, 'thing': 998, 'things': 999, 'think': 1000, 'this': 1001, 'thither': 1002, 'those': 1003, 'though': 1004, 'thought': 1005, 'three': 1006, 'threshold': 1007, 'threw': 1008, 'through': 1009, 'throwing': 1010, 'tie': 1011, 'till': 1012, 'time': 1013, 'timorously': 1014, 'tinge': 1015, 'tips': 1016, 'tired': 1017, 'to': 1018, 'told': 1019, 'tone': 1020, 'tones': 1021, 'too': 1022, 'took': 1023, 'tottering': 1024, 'touched': 1025, 'toward': 1026, 'trace': 1027, 'trade': 1028, 'transmute': 1029, 'traps': 1030, 'travelled': 1031, 'tribute': 1032, 'tributes': 1033, 'tricks': 1034, 'tried': 1035, 'trouser-presses': 1036, 'true': 1037, 'truth': 1038, 'turned': 1039, 'twenty': 1040, 'twenty-four': 1041, 'twice': 1042, 'twirling': 1043, 'unaccountable': 1044, 'uncertain': 1045, 'under': 1046, 'underlay': 1047, 'underneath': 1048, 'understand': 1049, 'unexpected': 1050, 'untouched': 1051, 'unusual': 1052, 'up': 1053, 'up-stream': 1054, 'upon': 1055, 'upset': 1056, 'upstairs': 1057, 'us': 1058, 'used': 1059, 'usual': 1060, 'value': 1061, 'varnishing': 1062, 'vases': 1063, 've': 1064, 'veins': 1065, 'velveteen': 1066, 'very': 1067, 'villa': 1068, 'vindicated': 1069, 'virtuosity': 1070, 'vista': 1071, 'vocation': 1072, 'voice': 1073, 'wall': 1074, 'wander': 1075, 'want': 1076, 'wanted': 1077, 'wants': 1078, 'was': 1079, 'wasn': 1080, 'watched': 1081, 'watching': 1082, 'water-colour': 1083, 'waves': 1084, 'way': 1085, 'weekly': 1086, 'weeks': 1087, 'welcome': 1088, 'went': 1089, 'were': 1090, 'what': 1091, 'when': 1092, 'whenever': 1093, 'where': 1094, 'which': 1095, 'while': 1096, 'white': 1097, 'white-panelled': 1098, 'who': 1099, 'whole': 1100, 'whom': 1101, 'why': 1102, 'wide': 1103, 'widow': 1104, 'wife': 1105, 'wild': 1106, 'wincing': 1107, 'window-curtains': 1108, 'wish': 1109, 'with': 1110, 'without': 1111, 'wits': 1112, 'woman': 1113, 'women': 1114, 'won': 1115, 'wonder': 1116, 'wondered': 1117, 'word': 1118, 'work': 1119, 'working': 1120, 'worth': 1121, 'would': 1122, 'wouldn': 1123, 'year': 1124, 'years': 1125, 'yellow': 1126, 'yet': 1127, 'you': 1128, 'younger': 1129, 'your': 1130, 'yourself': 1131}\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "print (vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3",
   "metadata": {},
   "source": [
    "- Below are the first 50 entries in this vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c5de4a-aa4e-4aec-b532-10bb364039d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n', 0)\n",
      "(' ', 1)\n",
      "('!', 2)\n",
      "('\"', 3)\n",
      "(\"'\", 4)\n",
      "('(', 5)\n",
      "(')', 6)\n",
      "(',', 7)\n",
      "('--', 8)\n",
      "('.', 9)\n",
      "(':', 10)\n",
      "(';', 11)\n",
      "('?', 12)\n",
      "('A', 13)\n",
      "('Ah', 14)\n",
      "('Among', 15)\n",
      "('And', 16)\n",
      "('Are', 17)\n",
      "('Arrt', 18)\n",
      "('As', 19)\n",
      "('At', 20)\n",
      "('Be', 21)\n",
      "('Begin', 22)\n",
      "('Burlington', 23)\n",
      "('But', 24)\n",
      "('By', 25)\n",
      "('Carlo', 26)\n",
      "('Chicago', 27)\n",
      "('Claude', 28)\n",
      "('Come', 29)\n",
      "('Croft', 30)\n",
      "('Destroyed', 31)\n",
      "('Devonshire', 32)\n",
      "('Don', 33)\n",
      "('Dubarry', 34)\n",
      "('Emperors', 35)\n",
      "('Florence', 36)\n",
      "('For', 37)\n",
      "('Gallery', 38)\n",
      "('Gideon', 39)\n",
      "('Gisburn', 40)\n",
      "('Gisburns', 41)\n",
      "('Grafton', 42)\n",
      "('Greek', 43)\n",
      "('Grindle', 44)\n",
      "('Grindles', 45)\n",
      "('HAD', 46)\n",
      "('Had', 47)\n",
      "('Hang', 48)\n",
      "('Has', 49)\n",
      "('He', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc314-351b-476a-9459-0ec9ddc29b19",
   "metadata": {},
   "source": [
    "- Below, we illustrate the tokenization of a short sample text using a small vocabulary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67407a9f-0202-4e7c-9ed7-1b3154191ebc",
   "metadata": {},
   "source": [
    "<img src=\"figures/05.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e569647-2589-4c9d-9a5c-aef1c88a0a9a",
   "metadata": {},
   "source": [
    "- Let's now put it all together into a tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f531bf46-7c25-4ef8-bff8-0d27518676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7",
   "metadata": {},
   "source": [
    "- The `encode` function turns text into token IDs\n",
    "- The `decode` function turns token IDs back into text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21d347-ec03-4823-b3d4-9d686e495617",
   "metadata": {},
   "source": [
    "<img src=\"figures/06.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2950a94-6b0d-474e-8ed0-66d0c3c1a95c",
   "metadata": {},
   "source": [
    "- We can use the tokenizer to encode (that is, tokenize) texts into integers\n",
    "- These integers can then be embedded (later) as input of/for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "647364ec-7995-4654-9b4a-7607ccf5f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 58, 4, 852, 990, 604, 535, 748, 7, 1128, 598, 7, 3, 69, 9, 40, 853, 1110, 756, 795, 9]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201706e-a487-4b60-b99d-5765865f29a0",
   "metadata": {},
   "source": [
    "- We can decode the integers back into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d8c8fb-432d-4a49-b332-99f23b233746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f6aa8b-9827-412e-9035-e827296ab0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ba34b-170f-4e71-939b-77aabb776f14",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.3 BytePair encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309494c-79cf-4a2d-bc28-a94d602f050e",
   "metadata": {},
   "source": [
    "- GPT-2 used BytePair encoding (BPE) as its tokenizer\n",
    "- it allows the model to break down words that aren't in its predefined vocabulary into smaller subword units or even individual characters, enabling it to handle out-of-vocabulary words\n",
    "- For instance, if GPT-2's vocabulary doesn't have the word \"unfamiliarword,\" it might tokenize it as [\"unfam\", \"iliar\", \"word\"] or some other subword breakdown, depending on its trained BPE merges\n",
    "- The original BPE tokenizer can be found here: [https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)\n",
    "- In this lecture, we are using the BPE tokenizer from OpenAI's open-source [tiktoken](https://github.com/openai/tiktoken) library, which implements its core algorithms in Rust to improve computational performance\n",
    "- (Based on an analysis [here](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/02_bonus_bytepair-encoder/compare-bpe-tiktoken.ipynb), I found that `tiktoken` is approx. 3x faster than the original tokenizer and 6x faster than an equivalent tokenizer in Hugging Face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ede1d41f-934b-4bf4-8184-54394a257a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48967a77-7d17-42bf-9e92-fc619d63a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff2cd85-7cfb-4325-b390-219938589428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45921, 75, 41495, 79, 727, 2571]\n"
     ]
    }
   ],
   "source": [
    "#text = (\n",
    "#    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "#     \"of someunknownPlace.\"\n",
    "#)\n",
    "text = \"growlmeatpoldarter\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d26a48bb-f82e-41a8-a955-a1c9cf9d50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode([75])\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2e7b4-6a22-42aa-8e4d-901f06378d4a",
   "metadata": {},
   "source": [
    "- BPE tokenizers break down unknown words into subwords and individual characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c082d41f-33d7-4827-97d8-993d5a84bb3c",
   "metadata": {},
   "source": [
    "<img src=\"figures/07.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb27ee-1156-457c-839e-eebb48d94d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"Akwirw ier\", allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd7c0d-70f8-4386-a114-907e96c950b0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.4 Data sampling with a sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d9826-6384-462e-aa8a-a7c73cd6aad0",
   "metadata": {},
   "source": [
    "- Above, we took care of the tokenization (converting text into word tokens represented as token ID numbers)\n",
    "- Now, let's talk about how we create the data loading for LLMs\n",
    "- We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb44f4-0c43-4a6a-9c2f-9cf31452354c",
   "metadata": {},
   "source": [
    "<img src=\"figures/08.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c",
   "metadata": {},
   "source": [
    "- For this, we use a sliding window approach, changing the position by +1:\n",
    "\n",
    "<img src=\"figures/09.png\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006212f-de45-468d-bdee-5806216d1679",
   "metadata": {},
   "source": [
    "- Note that in practice it's best to set the stride equal to the context length so that we don't have overlaps between the inputs (the targets are still shifted by +1 always)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3",
   "metadata": {},
   "source": [
    "<img src=\"figures/10.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc671fb-6945-4594-b33f-8b462a69720d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Exercise: Prepare your own favorite text dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
